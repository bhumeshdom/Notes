## LoRA
LoRA, or Low-Rank Adaptation, is a technique used to fine-tune large language models (LLMs) for specific tasks without having to train the entire model from scratch. This makes it possible to fine-tune LLMs more efficiently and with less data.

LoRA works by identifying the parts of the LLM that are most important for the task we are interested in. It then uses a low-rank update to adjust the parameters of these parts without affecting the rest of the model. This low-rank update is much more efficient than training the entire model from scratch.

